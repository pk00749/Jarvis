#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é˜¶æ®µ7ï¼šç³»ç»Ÿé›†æˆæµ‹è¯• - ç»¼åˆæµ‹è¯•å¥—ä»¶
æµ‹è¯•é¡¹ç›®ï¼š
1. ç«¯åˆ°ç«¯åŠŸèƒ½æµ‹è¯•
2. æ€§èƒ½å‹åŠ›æµ‹è¯•
3. è¯­éŸ³è¯†åˆ«å‡†ç¡®ç‡æµ‹è¯•
4. è¯­éŸ³åˆæˆè´¨é‡æµ‹è¯•
5. ç”¨æˆ·ç•Œé¢æ˜“ç”¨æ€§æµ‹è¯•
6. ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•ï¼ˆ24å°æ—¶è¿è¡Œï¼‰
7. å›å½’æµ‹è¯•ç¡®ä¿åŸæœ‰åŠŸèƒ½ä¸å—å½±å“
"""

import os
import sys
import time
import threading
import unittest
import numpy as np
import torch
import gc
from datetime import datetime, timedelta
import json
import wave
import librosa
from concurrent.futures import ThreadPoolExecutor, as_completed
import psutil
import GPUtil

# æ·»åŠ é¡¹ç›®è·¯å¾„
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(ROOT_DIR)

from jarvis import initialize_cosyvoice_optimized
from influence.influence import Influence
from listen.listen import Listen
from cosyvoice.cli.cosyvoice import CosyVoice2

class JarvisIntegrationTest(unittest.TestCase):
    """Jarvisç³»ç»Ÿé›†æˆæµ‹è¯•å¥—ä»¶"""

    @classmethod
    def setUpClass(cls):
        """æµ‹è¯•å‰çš„åˆå§‹åŒ–"""
        print("ğŸ§ª å¼€å§‹Jarvisç³»ç»Ÿé›†æˆæµ‹è¯•...")
        cls.start_time = time.time()

        # åˆå§‹åŒ–ç»„ä»¶
        try:
            cls.cosyvoice = initialize_cosyvoice_optimized()
            cls.influence = Influence()
            cls.listen = Listen()
            print("âœ… æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

        # æµ‹è¯•ç»“æœç»Ÿè®¡
        cls.test_results = {
            'total_tests': 0,
            'passed_tests': 0,
            'failed_tests': 0,
            'performance_metrics': {},
            'stability_metrics': {},
            'quality_metrics': {}
        }

    def setUp(self):
        """æ¯ä¸ªæµ‹è¯•å‰çš„å‡†å¤‡"""
        self.test_start_time = time.time()

    def tearDown(self):
        """æ¯ä¸ªæµ‹è¯•åçš„æ¸…ç†"""
        test_duration = time.time() - self.test_start_time
        print(f"â±ï¸  æµ‹è¯•è€—æ—¶: {test_duration:.2f}ç§’")

    def test_01_end_to_end_functionality(self):
        """1. ç«¯åˆ°ç«¯åŠŸèƒ½æµ‹è¯•"""
        print("\nğŸ” æµ‹è¯•1ï¼šç«¯åˆ°ç«¯åŠŸèƒ½æµ‹è¯•")

        # æµ‹è¯•æ ·æœ¬
        test_cases = [
            "ä»Šæ—¥å¤©æ°”ç‚¹æ ·ï¼Ÿ",
            "ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹å¹¿å·å˜…æƒ…å†µ",
            "å¸®æˆ‘è®²ä¸ªæ•…äº‹å¬ä¸‹"
        ]

        for i, test_text in enumerate(test_cases):
            print(f"æµ‹è¯•æ¡ˆä¾‹ {i+1}: {test_text}")

            try:
                # æ¨¡æ‹Ÿè¯­éŸ³è½¬æ–‡å­—
                start_time = time.time()

                # LLMå¤„ç†
                response = self.influence.llm(test_text)
                llm_time = time.time() - start_time

                # è¯­éŸ³åˆæˆ
                synthesis_start = time.time()
                for chunk in self.cosyvoice.inference_instruct2(
                    response, "å¥³æ€§ï¼Œæ¸©æŸ”ï¼Œç²¤è¯­", stream=True
                ):
                    pass  # æ¶ˆè´¹æµå¼è¾“å‡º
                synthesis_time = time.time() - synthesis_start

                total_time = time.time() - start_time

                print(f"  âœ… LLMå¤„ç†æ—¶é—´: {llm_time:.2f}s")
                print(f"  âœ… è¯­éŸ³åˆæˆæ—¶é—´: {synthesis_time:.2f}s")
                print(f"  âœ… æ€»å¤„ç†æ—¶é—´: {total_time:.2f}s")

                # è®°å½•æ€§èƒ½æŒ‡æ ‡
                self.test_results['performance_metrics'][f'case_{i+1}'] = {
                    'llm_time': llm_time,
                    'synthesis_time': synthesis_time,
                    'total_time': total_time
                }

                self.assertLess(total_time, 10, f"ç«¯åˆ°ç«¯å“åº”æ—¶é—´è¶…è¿‡10ç§’: {total_time:.2f}s")
                self.assertIsInstance(response, str)
                self.assertGreater(len(response), 0)

            except Exception as e:
                print(f"  âŒ æµ‹è¯•æ¡ˆä¾‹ {i+1} å¤±è´¥: {e}")
                self.fail(f"ç«¯åˆ°ç«¯åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")

    def test_02_performance_stress_test(self):
        """2. æ€§èƒ½å‹åŠ›æµ‹è¯•"""
        print("\nğŸš€ æµ‹è¯•2ï¼šæ€§èƒ½å‹åŠ›æµ‹è¯•")

        # å¹¶å‘æµ‹è¯•å‚æ•°
        num_concurrent = 3  # å¹¶å‘æ•°é‡
        test_duration = 60  # æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰

        def single_request():
            """å•ä¸ªè¯·æ±‚å¤„ç†"""
            try:
                start_time = time.time()
                response = self.influence.llm("ä½ å¥½")

                # è¯­éŸ³åˆæˆ
                for chunk in self.cosyvoice.inference_instruct2(
                    response[:50], "å¥³æ€§ï¼Œæ¸©æŸ”ï¼Œç²¤è¯­", stream=True
                ):
                    pass

                return time.time() - start_time
            except Exception as e:
                return None

        # æ‰§è¡Œå¹¶å‘æµ‹è¯•
        start_time = time.time()
        completed_requests = 0
        failed_requests = 0
        response_times = []

        with ThreadPoolExecutor(max_workers=num_concurrent) as executor:
            futures = []

            while time.time() - start_time < test_duration:
                future = executor.submit(single_request)
                futures.append(future)
                time.sleep(0.5)  # æ§åˆ¶è¯·æ±‚é¢‘ç‡

            # æ”¶é›†ç»“æœ
            for future in as_completed(futures):
                result = future.result()
                if result is not None:
                    completed_requests += 1
                    response_times.append(result)
                else:
                    failed_requests += 1

        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        if response_times:
            avg_response_time = np.mean(response_times)
            p95_response_time = np.percentile(response_times, 95)
            success_rate = completed_requests / (completed_requests + failed_requests) * 100

            print(f"  âœ… å®Œæˆè¯·æ±‚æ•°: {completed_requests}")
            print(f"  âœ… å¤±è´¥è¯·æ±‚æ•°: {failed_requests}")
            print(f"  âœ… æˆåŠŸç‡: {success_rate:.1f}%")
            print(f"  âœ… å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}s")
            print(f"  âœ… 95%å“åº”æ—¶é—´: {p95_response_time:.2f}s")

            self.test_results['performance_metrics']['stress_test'] = {
                'completed_requests': completed_requests,
                'failed_requests': failed_requests,
                'success_rate': success_rate,
                'avg_response_time': avg_response_time,
                'p95_response_time': p95_response_time
            }

            self.assertGreater(success_rate, 95, f"æˆåŠŸç‡è¿‡ä½: {success_rate:.1f}%")
            self.assertLess(avg_response_time, 8, f"å¹³å‡å“åº”æ—¶é—´è¿‡é•¿: {avg_response_time:.2f}s")
        else:
            self.fail("å‹åŠ›æµ‹è¯•æœªè·å¾—ä»»ä½•æœ‰æ•ˆå“åº”")

    def test_03_speech_recognition_accuracy(self):
        """3. è¯­éŸ³è¯†åˆ«å‡†ç¡®ç‡æµ‹è¯•"""
        print("\nğŸ¤ æµ‹è¯•3ï¼šè¯­éŸ³è¯†åˆ«å‡†ç¡®ç‡æµ‹è¯•")

        # æŸ¥æ‰¾æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
        recordings_dir = os.path.join(ROOT_DIR, 'recordings')
        audio_files = [f for f in os.listdir(recordings_dir) if f.endswith('.wav')][:5]

        if not audio_files:
            print("  âš ï¸  æœªæ‰¾åˆ°æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼Œè·³è¿‡è¯­éŸ³è¯†åˆ«æµ‹è¯•")
            return

        recognition_results = []

        for audio_file in audio_files:
            audio_path = os.path.join(recordings_dir, audio_file)

            try:
                # æ‰§è¡Œè¯­éŸ³è¯†åˆ«
                start_time = time.time()
                result = self.influence.voice_to_text(audio_path)
                recognition_time = time.time() - start_time

                print(f"  ğŸµ {audio_file}: {result} (è€—æ—¶: {recognition_time:.2f}s)")

                recognition_results.append({
                    'file': audio_file,
                    'result': result,
                    'time': recognition_time,
                    'success': len(result) > 0
                })

            except Exception as e:
                print(f"  âŒ è¯†åˆ«å¤±è´¥ {audio_file}: {e}")
                recognition_results.append({
                    'file': audio_file,
                    'result': "",
                    'time': 0,
                    'success': False
                })

        # è®¡ç®—å‡†ç¡®ç‡
        successful_recognitions = sum(1 for r in recognition_results if r['success'])
        accuracy_rate = successful_recognitions / len(recognition_results) * 100
        avg_recognition_time = np.mean([r['time'] for r in recognition_results if r['success']])

        print(f"  âœ… è¯†åˆ«æˆåŠŸç‡: {accuracy_rate:.1f}%")
        print(f"  âœ… å¹³å‡è¯†åˆ«æ—¶é—´: {avg_recognition_time:.2f}s")

        self.test_results['quality_metrics']['speech_recognition'] = {
            'accuracy_rate': accuracy_rate,
            'avg_recognition_time': avg_recognition_time,
            'total_files_tested': len(recognition_results)
        }

        self.assertGreater(accuracy_rate, 80, f"è¯­éŸ³è¯†åˆ«å‡†ç¡®ç‡è¿‡ä½: {accuracy_rate:.1f}%")

    def test_04_speech_synthesis_quality(self):
        """4. è¯­éŸ³åˆæˆè´¨é‡æµ‹è¯•"""
        print("\nğŸ”Š æµ‹è¯•4ï¼šè¯­éŸ³åˆæˆè´¨é‡æµ‹è¯•")

        test_texts = [
            "ä½ å¥½ï¼Œæˆ‘ä¿‚Jarvis",
            "ä»Šæ—¥å¤©æ°”çœŸä¿‚å¥½å¥½",
            "å¤šè°¢ä½ ä½¿ç”¨æˆ‘å“‹å˜…ç³»ç»Ÿ",
            "æœ‰å’©å¯ä»¥å¸®åˆ°ä½ ï¼Ÿ"
        ]

        synthesis_results = []

        for i, text in enumerate(test_texts):
            try:
                start_time = time.time()
                audio_chunks = []

                # æµ‹è¯•æµå¼åˆæˆ
                for chunk in self.cosyvoice.inference_instruct2(
                    text, "å¥³æ€§ï¼Œæ¸©æŸ”ï¼Œç²¤è¯­", stream=True
                ):
                    if chunk is not None:
                        audio_chunks.append(chunk)

                synthesis_time = time.time() - start_time

                print(f"  ğŸµ æ–‡æœ¬ {i+1}: \"{text}\"")
                print(f"     åˆæˆæ—¶é—´: {synthesis_time:.2f}s")
                print(f"     éŸ³é¢‘å—æ•°é‡: {len(audio_chunks)}")

                synthesis_results.append({
                    'text': text,
                    'synthesis_time': synthesis_time,
                    'chunks_count': len(audio_chunks),
                    'success': len(audio_chunks) > 0
                })

                # æ£€æŸ¥æ˜¯å¦æœ‰æç¤ºè¯æ··å…¥
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„éŸ³é¢‘åˆ†æé€»è¾‘

            except Exception as e:
                print(f"  âŒ åˆæˆå¤±è´¥ {i+1}: {e}")
                synthesis_results.append({
                    'text': text,
                    'synthesis_time': 0,
                    'chunks_count': 0,
                    'success': False
                })

        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        successful_synthesis = sum(1 for r in synthesis_results if r['success'])
        success_rate = successful_synthesis / len(synthesis_results) * 100
        avg_synthesis_time = np.mean([r['synthesis_time'] for r in synthesis_results if r['success']])

        print(f"  âœ… åˆæˆæˆåŠŸç‡: {success_rate:.1f}%")
        print(f"  âœ… å¹³å‡åˆæˆæ—¶é—´: {avg_synthesis_time:.2f}s")

        self.test_results['quality_metrics']['speech_synthesis'] = {
            'success_rate': success_rate,
            'avg_synthesis_time': avg_synthesis_time,
            'total_texts_tested': len(synthesis_results)
        }

        self.assertGreater(success_rate, 95, f"è¯­éŸ³åˆæˆæˆåŠŸç‡è¿‡ä½: {success_rate:.1f}%")
        self.assertLess(avg_synthesis_time, 3, f"å¹³å‡åˆæˆæ—¶é—´è¿‡é•¿: {avg_synthesis_time:.2f}s")

    def test_05_cantonese_llm_quality(self):
        """5. ç²¤è¯­LLMå›å¤è´¨é‡æµ‹è¯•"""
        print("\nğŸ—£ï¸  æµ‹è¯•5ï¼šç²¤è¯­LLMå›å¤è´¨é‡æµ‹è¯•")

        test_cases = [
            {
                'input': 'ä½ å¥½',
                'expected_keywords': ['ä½ å¥½', 'ä¿‚', 'å˜…', 'å’©']
            },
            {
                'input': 'ä»Šæ—¥å¤©æ°”ç‚¹æ ·ï¼Ÿ',
                'expected_keywords': ['å¤©æ°”', 'ä»Šæ—¥', 'ä¿‚', 'å˜…']
            },
            {
                'input': 'å¯å””å¯ä»¥å¸®æˆ‘ï¼Ÿ',
                'expected_keywords': ['å¯ä»¥', 'å¸®', 'ä½ ', 'ä¿‚']
            }
        ]

        cantonese_quality_scores = []

        for i, case in enumerate(test_cases):
            try:
                start_time = time.time()
                response = self.influence.llm(case['input'])
                response_time = time.time() - start_time

                print(f"  ğŸ’¬ è¾“å…¥: {case['input']}")
                print(f"     å›å¤: {response}")
                print(f"     å“åº”æ—¶é—´: {response_time:.2f}s")

                # æ£€æŸ¥ç²¤è¯­å…³é”®è¯å‡ºç°æƒ…å†µ
                cantonese_keywords_found = 0
                for keyword in case['expected_keywords']:
                    if keyword in response:
                        cantonese_keywords_found += 1

                quality_score = cantonese_keywords_found / len(case['expected_keywords']) * 100
                cantonese_quality_scores.append(quality_score)

                print(f"     ç²¤è¯­è´¨é‡å¾—åˆ†: {quality_score:.1f}%")

            except Exception as e:
                print(f"  âŒ LLMæµ‹è¯•å¤±è´¥ {i+1}: {e}")
                cantonese_quality_scores.append(0)

        avg_cantonese_quality = np.mean(cantonese_quality_scores)
        print(f"  âœ… å¹³å‡ç²¤è¯­è´¨é‡å¾—åˆ†: {avg_cantonese_quality:.1f}%")

        self.test_results['quality_metrics']['cantonese_llm'] = {
            'avg_quality_score': avg_cantonese_quality,
            'individual_scores': cantonese_quality_scores
        }

        self.assertGreater(avg_cantonese_quality, 60, f"ç²¤è¯­LLMè´¨é‡å¾—åˆ†è¿‡ä½: {avg_cantonese_quality:.1f}%")

    def test_06_system_stability_short(self):
        """6. ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•ï¼ˆçŸ­æœŸç‰ˆæœ¬ï¼Œæ›¿ä»£24å°æ—¶æµ‹è¯•ï¼‰"""
        print("\nâš¡ æµ‹è¯•6ï¼šç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•ï¼ˆ10åˆ†é’Ÿç‰ˆæœ¬ï¼‰")

        test_duration = 600  # 10åˆ†é’Ÿ
        check_interval = 30  # 30ç§’æ£€æŸ¥ä¸€æ¬¡

        start_time = time.time()
        stability_checks = []
        error_count = 0

        print(f"  å¼€å§‹10åˆ†é’Ÿç¨³å®šæ€§æµ‹è¯•...")

        while time.time() - start_time < test_duration:
            try:
                check_start = time.time()

                # æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„å¤„ç†æµç¨‹
                test_text = "ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•"
                response = self.influence.llm(test_text)

                # ç®€çŸ­çš„è¯­éŸ³åˆæˆæµ‹è¯•
                chunk_count = 0
                for chunk in self.cosyvoice.inference_instruct2(
                    response[:30], "å¥³æ€§ï¼Œæ¸©æŸ”ï¼Œç²¤è¯­", stream=True
                ):
                    chunk_count += 1
                    if chunk_count >= 3:  # é™åˆ¶æµ‹è¯•é•¿åº¦
                        break

                check_time = time.time() - check_start

                # è®°å½•ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
                memory_usage = psutil.virtual_memory().percent
                cpu_usage = psutil.cpu_percent()

                stability_checks.append({
                    'timestamp': time.time(),
                    'response_time': check_time,
                    'memory_usage': memory_usage,
                    'cpu_usage': cpu_usage,
                    'success': True
                })

                elapsed = time.time() - start_time
                remaining = test_duration - elapsed
                print(f"  â±ï¸  å·²è¿è¡Œ {elapsed:.0f}sï¼Œå‰©ä½™ {remaining:.0f}s (å†…å­˜: {memory_usage:.1f}%, CPU: {cpu_usage:.1f}%)")

            except Exception as e:
                error_count += 1
                print(f"  âŒ ç¨³å®šæ€§æ£€æŸ¥å¤±è´¥: {e}")
                stability_checks.append({
                    'timestamp': time.time(),
                    'response_time': None,
                    'memory_usage': None,
                    'cpu_usage': None,
                    'success': False,
                    'error': str(e)
                })

            # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
            time.sleep(check_interval)

        # è®¡ç®—ç¨³å®šæ€§æŒ‡æ ‡
        successful_checks = sum(1 for check in stability_checks if check['success'])
        total_checks = len(stability_checks)
        stability_rate = successful_checks / total_checks * 100 if total_checks > 0 else 0

        if successful_checks > 0:
            avg_response_time = np.mean([check['response_time'] for check in stability_checks if check['success']])
            avg_memory_usage = np.mean([check['memory_usage'] for check in stability_checks if check['success']])
            avg_cpu_usage = np.mean([check['cpu_usage'] for check in stability_checks if check['success']])
        else:
            avg_response_time = avg_memory_usage = avg_cpu_usage = 0

        print(f"  âœ… ç¨³å®šæ€§æµ‹è¯•å®Œæˆ")
        print(f"  âœ… æ€»æ£€æŸ¥æ¬¡æ•°: {total_checks}")
        print(f"  âœ… æˆåŠŸæ¬¡æ•°: {successful_checks}")
        print(f"  âœ… ç¨³å®šç‡: {stability_rate:.1f}%")
        print(f"  âœ… å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}s")
        print(f"  âœ… å¹³å‡å†…å­˜ä½¿ç”¨: {avg_memory_usage:.1f}%")
        print(f"  âœ… å¹³å‡CPUä½¿ç”¨: {avg_cpu_usage:.1f}%")

        self.test_results['stability_metrics'] = {
            'total_checks': total_checks,
            'successful_checks': successful_checks,
            'stability_rate': stability_rate,
            'avg_response_time': avg_response_time,
            'avg_memory_usage': avg_memory_usage,
            'avg_cpu_usage': avg_cpu_usage,
            'error_count': error_count
        }

        self.assertGreater(stability_rate, 95, f"ç³»ç»Ÿç¨³å®šç‡è¿‡ä½: {stability_rate:.1f}%")
        self.assertLess(avg_memory_usage, 80, f"å¹³å‡å†…å­˜ä½¿ç”¨è¿‡é«˜: {avg_memory_usage:.1f}%")

    def test_07_regression_test(self):
        """7. å›å½’æµ‹è¯•ç¡®ä¿åŸæœ‰åŠŸèƒ½ä¸å—å½±å“"""
        print("\nğŸ”„ æµ‹è¯•7ï¼šå›å½’æµ‹è¯•")

        # æµ‹è¯•åŸºç¡€ç»„ä»¶åŠŸèƒ½
        regression_results = {}

        # 1. æµ‹è¯•Influenceç»„ä»¶
        try:
            test_text = "Hello"
            result = self.influence.llm(test_text)
            regression_results['influence_llm'] = len(result) > 0
            print("  âœ… Influence.llm åŠŸèƒ½æ­£å¸¸")
        except Exception as e:
            regression_results['influence_llm'] = False
            print(f"  âŒ Influence.llm åŠŸèƒ½å¼‚å¸¸: {e}")

        # 2. æµ‹è¯•CosyVoiceç»„ä»¶
        try:
            test_text = "æµ‹è¯•"
            chunks = list(self.cosyvoice.inference_instruct2(
                test_text, "å¥³æ€§ï¼Œæ¸©æŸ”ï¼Œç²¤è¯­", stream=True
            ))
            regression_results['cosyvoice_synthesis'] = len(chunks) > 0
            print("  âœ… CosyVoice2è¯­éŸ³åˆæˆåŠŸèƒ½æ­£å¸¸")
        except Exception as e:
            regression_results['cosyvoice_synthesis'] = False
            print(f"  âŒ CosyVoice2è¯­éŸ³åˆæˆåŠŸèƒ½å¼‚å¸¸: {e}")

        # 3. æµ‹è¯•Listenç»„ä»¶ï¼ˆå¦‚æœæœ‰éŸ³é¢‘æ–‡ä»¶ï¼‰
        recordings_dir = os.path.join(ROOT_DIR, 'recordings')
        if os.path.exists(recordings_dir):
            audio_files = [f for f in os.listdir(recordings_dir) if f.endswith('.wav')]
            if audio_files:
                try:
                    audio_path = os.path.join(recordings_dir, audio_files[0])
                    result = self.influence.voice_to_text(audio_path)
                    regression_results['speech_recognition'] = len(result) > 0
                    print("  âœ… è¯­éŸ³è¯†åˆ«åŠŸèƒ½æ­£å¸¸")
                except Exception as e:
                    regression_results['speech_recognition'] = False
                    print(f"  âŒ è¯­éŸ³è¯†åˆ«åŠŸèƒ½å¼‚å¸¸: {e}")
            else:
                regression_results['speech_recognition'] = None
                print("  âš ï¸  æ— éŸ³é¢‘æ–‡ä»¶ï¼Œè·³è¿‡è¯­éŸ³è¯†åˆ«æµ‹è¯•")
        else:
            regression_results['speech_recognition'] = None
            print("  âš ï¸  recordingsç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡è¯­éŸ³è¯†åˆ«æµ‹è¯•")

        # ç»Ÿè®¡å›å½’æµ‹è¯•ç»“æœ
        tested_functions = [k for k, v in regression_results.items() if v is not None]
        passed_functions = [k for k, v in regression_results.items() if v is True]

        regression_rate = len(passed_functions) / len(tested_functions) * 100 if tested_functions else 0

        print(f"  âœ… å›å½’æµ‹è¯•é€šè¿‡ç‡: {regression_rate:.1f}%")
        print(f"  âœ… æµ‹è¯•åŠŸèƒ½æ•°: {len(tested_functions)}")
        print(f"  âœ… é€šè¿‡åŠŸèƒ½æ•°: {len(passed_functions)}")

        self.test_results['regression_results'] = regression_results

        self.assertGreater(regression_rate, 95, f"å›å½’æµ‹è¯•é€šè¿‡ç‡è¿‡ä½: {regression_rate:.1f}%")

    @classmethod
    def tearDownClass(cls):
        """æµ‹è¯•å®Œæˆåçš„æ¸…ç†å’ŒæŠ¥å‘Šç”Ÿæˆ"""
        total_time = time.time() - cls.start_time

        print(f"\nğŸ ç³»ç»Ÿé›†æˆæµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")

        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        test_report = {
            'test_timestamp': datetime.now().isoformat(),
            'total_test_time': total_time,
            'test_results': cls.test_results,
            'system_info': {
                'platform': sys.platform,
                'python_version': sys.version,
                'torch_version': torch.__version__ if hasattr(torch, '__version__') else 'N/A'
            }
        }

        # ä¿å­˜æµ‹è¯•æŠ¥å‘Š
        report_path = os.path.join(ROOT_DIR, 'tests', 'integration_test_report.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(test_report, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“Š æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")

        # å†…å­˜æ¸…ç†
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

def run_integration_tests():
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    unittest.main(argv=[''], exit=False, verbosity=2)

if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨Jarvisç³»ç»Ÿé›†æˆæµ‹è¯•...")
    run_integration_tests()
